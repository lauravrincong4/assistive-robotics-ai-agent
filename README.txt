# ü§ñ Assistive Robotics AI Agent

Este repositorio contiene un pipeline de inteligencia artificial dise√±ado para analizar art√≠culos cient√≠ficos en PDF y extraer autom√°ticamente informaci√≥n clave sobre brazos rob√≥ticos y tipos de gripper. Est√° orientado a apoyar investigaciones en rob√≥tica asistencial, utilizando modelos de lenguaje locales para maximizar la privacidad y el rendimiento.

## üöÄ Funcionalidades principales

- üìÑ Lectura automatizada de documentos cient√≠ficos en PDF
- üß† Segmentaci√≥n por chunks y detecci√≥n de idioma
- üéØ Extracci√≥n inteligente de:
  - Tipos de estructuras de brazo rob√≥tico
  - Tipos de gripper o efector final
  - Tipo de documento (art√≠culo, tesis, revisi√≥n, etc.)
  - Dominio de aplicaci√≥n (hogar, salud, industria, etc.)
- ‚ö° Procesamiento paralelo con **detenci√≥n anticipada** (early stopping) para acelerar el an√°lisis

---

## üóÇÔ∏è Estructura del proyecto

```
assistive-robotics-ai-agent/
‚îú‚îÄ‚îÄ README.md               # Descripci√≥n del proyecto
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias necesarias
‚îú‚îÄ‚îÄ .gitignore              # Archivos ignorados por Git
‚îú‚îÄ‚îÄ notebooks/              # Cuadernos Jupyter (an√°lisis, pruebas)
‚îú‚îÄ‚îÄ src/                    # C√≥digo fuente del agente
‚îú‚îÄ‚îÄ models/                 # Modelos locales si se usan
‚îî‚îÄ‚îÄ docs/                   # Documentaci√≥n adicional
```

---

## üíª Instrucciones para usarlo en VS Code

### 1. Requisitos previos

- Tener instalado [Python 3.10+](https://www.python.org/)
- Tener [VS Code](https://code.visualstudio.com/) con extensiones recomendadas:
  - Python
  - Jupyter
- Tener [Git](https://git-scm.com/) instalado y configurado (opcional)
- Tener [Ollama](https://ollama.com/) instalado y corriendo localmente

### 2. Clona el repositorio

```bash
git clone https://github.com/lauravrincong4/assistive-robotics-ai-agent.git
cd assistive-robotics-ai-agent
```

### 3. Crea y activa un entorno virtual con Conda

```bash
conda create -n roboarm-gpu python=3.10
conda activate roboarm-gpu
```

### 4. Instala las dependencias

```bash
pip install -r requirements.txt
```

### 5. Abre el proyecto en VS Code

Desde la terminal:

```bash
code .
```

> Aseg√∫rate de seleccionar el entorno `roboarm-gpu` como kernel si usas notebooks.

---

## ‚öôÔ∏è Ejemplo de uso

Puedes ejecutar el pipeline desde un Jupyter Notebook en `notebooks/` o usar scripts desde `src/` como este:

```python
from langchain_ollama import OllamaLLM

llm = OllamaLLM(model="llama2")
respuesta = llm.invoke("¬øQu√© estructuras de brazo rob√≥tico son m√°s comunes?")
print(respuesta)
```

---

## üß† Consideraciones adicionales

- Este proyecto puede funcionar **100% offline** con modelos locales como `llama-cpp-python`
- Se recomienda usar modelos ligeros (`llama2:7b`, `mistral`, `gemma`) si no cuentas con una GPU potente
- Puedes activar la detenci√≥n anticipada en el c√≥digo para acelerar el procesamiento masivo de PDFs
